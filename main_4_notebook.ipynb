{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langgraph in .\\.venv\\lib\\site-packages (0.3.22)\n",
      "Requirement already satisfied: langchain_community in .\\.venv\\lib\\site-packages (0.3.20)\n",
      "Requirement already satisfied: langchain_anthropic in .\\.venv\\lib\\site-packages (0.3.10)\n",
      "Requirement already satisfied: langchain_experimental in .\\.venv\\lib\\site-packages (0.3.4)\n",
      "Requirement already satisfied: langchain-core<0.4,>=0.1 in .\\.venv\\lib\\site-packages (from langgraph) (0.3.48)\n",
      "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.10 in .\\.venv\\lib\\site-packages (from langgraph) (2.0.23)\n",
      "Requirement already satisfied: langgraph-prebuilt<0.2,>=0.1.1 in .\\.venv\\lib\\site-packages (from langgraph) (0.1.4)\n",
      "Requirement already satisfied: langgraph-sdk<0.2.0,>=0.1.42 in .\\.venv\\lib\\site-packages (from langgraph) (0.1.58)\n",
      "Requirement already satisfied: xxhash<4.0.0,>=3.5.0 in .\\.venv\\lib\\site-packages (from langgraph) (3.5.0)\n",
      "Requirement already satisfied: langchain<1.0.0,>=0.3.21 in .\\.venv\\lib\\site-packages (from langchain_community) (0.3.21)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in .\\.venv\\lib\\site-packages (from langchain_community) (2.0.39)\n",
      "Requirement already satisfied: requests<3,>=2 in .\\.venv\\lib\\site-packages (from langchain_community) (2.32.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in .\\.venv\\lib\\site-packages (from langchain_community) (6.0.2)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in .\\.venv\\lib\\site-packages (from langchain_community) (3.11.14)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in .\\.venv\\lib\\site-packages (from langchain_community) (9.0.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in .\\.venv\\lib\\site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: pydantic-settings<3.0.0,>=2.4.0 in .\\.venv\\lib\\site-packages (from langchain_community) (2.8.1)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in .\\.venv\\lib\\site-packages (from langchain_community) (0.3.18)\n",
      "Requirement already satisfied: httpx-sse<1.0.0,>=0.4.0 in .\\.venv\\lib\\site-packages (from langchain_community) (0.4.0)\n",
      "Requirement already satisfied: numpy<3,>=1.26.2 in .\\.venv\\lib\\site-packages (from langchain_community) (2.2.4)\n",
      "Requirement already satisfied: anthropic<1,>=0.49.0 in .\\.venv\\lib\\site-packages (from langchain_anthropic) (0.49.0)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in .\\.venv\\lib\\site-packages (from langchain_anthropic) (2.10.6)\n",
      "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in .\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (2.6.1)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in .\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.2)\n",
      "Requirement already satisfied: attrs>=17.3.0 in .\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (25.3.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in .\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.5.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in .\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.2.0)\n",
      "Requirement already satisfied: propcache>=0.2.0 in .\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (0.3.0)\n",
      "Requirement already satisfied: yarl<2.0,>=1.17.0 in .\\.venv\\lib\\site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.18.3)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in .\\.venv\\lib\\site-packages (from anthropic<1,>=0.49.0->langchain_anthropic) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in .\\.venv\\lib\\site-packages (from anthropic<1,>=0.49.0->langchain_anthropic) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in .\\.venv\\lib\\site-packages (from anthropic<1,>=0.49.0->langchain_anthropic) (0.28.1)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in .\\.venv\\lib\\site-packages (from anthropic<1,>=0.49.0->langchain_anthropic) (0.9.0)\n",
      "Requirement already satisfied: sniffio in .\\.venv\\lib\\site-packages (from anthropic<1,>=0.49.0->langchain_anthropic) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in .\\.venv\\lib\\site-packages (from anthropic<1,>=0.49.0->langchain_anthropic) (4.12.2)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in .\\.venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.26.1)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in .\\.venv\\lib\\site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: langchain-text-splitters<1.0.0,>=0.3.7 in .\\.venv\\lib\\site-packages (from langchain<1.0.0,>=0.3.21->langchain_community) (0.3.7)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in .\\.venv\\lib\\site-packages (from langchain-core<0.4,>=0.1->langgraph) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in .\\.venv\\lib\\site-packages (from langchain-core<0.4,>=0.1->langgraph) (24.2)\n",
      "Requirement already satisfied: ormsgpack<2.0.0,>=1.8.0 in .\\.venv\\lib\\site-packages (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph) (1.9.0)\n",
      "Requirement already satisfied: orjson>=3.10.1 in .\\.venv\\lib\\site-packages (from langgraph-sdk<0.2.0,>=0.1.42->langgraph) (3.10.16)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in .\\.venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in .\\.venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in .\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain_anthropic) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in .\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain_anthropic) (2.27.2)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in .\\.venv\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.0.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in .\\.venv\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.4.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in .\\.venv\\lib\\site-packages (from requests<3,>=2->langchain_community) (3.10)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in .\\.venv\\lib\\site-packages (from requests<3,>=2->langchain_community) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in .\\.venv\\lib\\site-packages (from requests<3,>=2->langchain_community) (2025.1.31)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in .\\.venv\\lib\\site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.1.1)\n",
      "Requirement already satisfied: httpcore==1.* in .\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->anthropic<1,>=0.49.0->langchain_anthropic) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in .\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->anthropic<1,>=0.49.0->langchain_anthropic) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in .\\.venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.1->langgraph) (3.0.0)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in .\\.venv\\lib\\site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -U langgraph langchain_community langchain_anthropic langchain_experimental"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in .\\.venv\\lib\\site-packages (1.0.1)\n",
      "Requirement already satisfied: langchain_groq in .\\.venv\\lib\\site-packages (0.3.1)\n",
      "Requirement already satisfied: langchain_ollama in .\\.venv\\lib\\site-packages (0.3.0)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.47 in .\\.venv\\lib\\site-packages (from langchain_groq) (0.3.48)\n",
      "Requirement already satisfied: groq<1,>=0.4.1 in .\\.venv\\lib\\site-packages (from langchain_groq) (0.20.0)\n",
      "Requirement already satisfied: ollama<1,>=0.4.4 in .\\.venv\\lib\\site-packages (from langchain_ollama) (0.4.7)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in .\\.venv\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (4.9.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in .\\.venv\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (1.9.0)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in .\\.venv\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (0.28.1)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in .\\.venv\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (2.10.6)\n",
      "Requirement already satisfied: sniffio in .\\.venv\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (1.3.1)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in .\\.venv\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (4.12.2)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in .\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.47->langchain_groq) (0.3.18)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in .\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.47->langchain_groq) (9.0.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in .\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.47->langchain_groq) (1.33)\n",
      "Requirement already satisfied: PyYAML>=5.3 in .\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.47->langchain_groq) (6.0.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in .\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.47->langchain_groq) (24.2)\n",
      "Requirement already satisfied: idna>=2.8 in .\\.venv\\lib\\site-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain_groq) (3.10)\n",
      "Requirement already satisfied: certifi in .\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in .\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in .\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in .\\.venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.47->langchain_groq) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in .\\.venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.47->langchain_groq) (3.10.16)\n",
      "Requirement already satisfied: requests<3,>=2 in .\\.venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.47->langchain_groq) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in .\\.venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.47->langchain_groq) (1.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in .\\.venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.47->langchain_groq) (0.23.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in .\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain_groq) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in .\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain_groq) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in .\\.venv\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.47->langchain_groq) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in .\\.venv\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.47->langchain_groq) (2.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.3.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install python-dotenv langchain_groq langchain_ollama\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import getpass\n",
    "import os\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "from langchain_ollama import ChatOllama\n",
    "\n",
    "dotenv_path = find_dotenv()\n",
    "load_dotenv(dotenv_path)\n",
    "groq_api_key = os.getenv(\"groq_api_key\")\n",
    "os.environ[\"groq_api_key\"] = groq_api_key \n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "\n",
    "_set_env(\"groq_api_key\")\n",
    "\n",
    "dotenv_path = find_dotenv()\n",
    "load_dotenv(dotenv_path)\n",
    "tavily_api_key = os.getenv(\"tavily_api_key\")\n",
    "os.environ[\"tavily_api_key\"] = tavily_api_key\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"tavily_api_key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<>:23: SyntaxWarning: invalid escape sequence '\\`'\n",
      "<>:23: SyntaxWarning: invalid escape sequence '\\`'\n",
      "<>:23: SyntaxWarning: invalid escape sequence '\\`'\n",
      "<>:23: SyntaxWarning: invalid escape sequence '\\`'\n",
      "C:\\Users\\paulo\\AppData\\Local\\Temp\\ipykernel_7296\\484249122.py:23: SyntaxWarning: invalid escape sequence '\\`'\n",
      "  result_str = f\"Successfully executed:\\n\\`\\`\\`python\\n{code}\\n\\`\\`\\`\\nStdout: {result}\"\n",
      "C:\\Users\\paulo\\AppData\\Local\\Temp\\ipykernel_7296\\484249122.py:23: SyntaxWarning: invalid escape sequence '\\`'\n",
      "  result_str = f\"Successfully executed:\\n\\`\\`\\`python\\n{code}\\n\\`\\`\\`\\nStdout: {result}\"\n"
     ]
    }
   ],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "from langchain_core.tools import tool\n",
    "from langchain_experimental.utilities import PythonREPL\n",
    "\n",
    "tavily_tool = TavilySearchResults(max_results=5)\n",
    "\n",
    "# This executes code locally, which can be unsafe\n",
    "repl = PythonREPL()\n",
    "\n",
    "\n",
    "@tool\n",
    "def python_repl_tool(\n",
    "    code: Annotated[str, \"The python code to execute to generate your chart.\"],\n",
    "):\n",
    "    \"\"\"Use this to execute python code and do math. If you want to see the output of a value,\n",
    "    you should print it out with `print(...)`. This is visible to the user.\"\"\"\n",
    "    try:\n",
    "        result = repl.run(code)\n",
    "    except BaseException as e:\n",
    "        return f\"Failed to execute. Error: {repr(e)}\"\n",
    "    result_str = f\"Successfully executed:\\n\\`\\`\\`python\\n{code}\\n\\`\\`\\`\\nStdout: {result}\"\n",
    "    return result_str\n",
    "\n",
    "@tool\n",
    "def custom_string_tool() -> str:\n",
    "    \"\"\"Returns a specific string when called.\"\"\"\n",
    "    return \"This is the specific string you requested.\"\n",
    "\n",
    "\n",
    "@tool\n",
    "def custom_summary_report_tool() -> str:\n",
    "    \"\"\"Returns a summary report\"\"\"\n",
    "    return \"This is the summary report. 2023: Total Food - 99200, Total Transpo - 30900, Total Daily - 18750; 2024: Total Food - 104800, Total Transpo - 32750, Total Daily - 21100\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Literal\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from langgraph.graph import MessagesState, END\n",
    "from langgraph.types import Command\n",
    "\n",
    "\n",
    "members = [\"researcher\", \"coder\", \"expenses_manager\"]\n",
    "# Our team supervisor is an LLM node. It just picks the next agent to process\n",
    "# and decides when the work is completed\n",
    "options = members + [\"FINISH\"]\n",
    "\n",
    "system_prompt = (\n",
    "    \"You are a supervisor tasked with managing a conversation between the\"\n",
    "    f\" following workers: {members}. Given the following user request,\"\n",
    "    \" respond with the worker to act next. Each worker will perform a\"\n",
    "    \" task and respond with their results and status. When finished,\"\n",
    "    \" respond with FINISH.\"\n",
    ")\n",
    "\n",
    "\n",
    "class Router(TypedDict):\n",
    "    \"\"\"Worker to route to next. If no workers needed, route to FINISH.\"\"\"\n",
    "\n",
    "    next: Literal[*options]\n",
    "\n",
    "\n",
    "#llm = ChatAnthropic(model=\"claude-3-5-sonnet-latest\")\n",
    "\n",
    "llm=ChatGroq(groq_api_key=groq_api_key,model_name=\"Llama-3.3-70b-Versatile\")\n",
    "llm_tool=ChatGroq(groq_api_key=groq_api_key,model_name=\"Llama-3.3-70b-Versatile\")\n",
    "#MODEL_NAME = \"deepseek-r1:latest\"\n",
    "\n",
    "#MODEL_NAME = \"gemma3:4b\"\n",
    "MODEL_NAME = \"llama3.2:latest\"\n",
    "#llm = ChatOllama(model=MODEL_NAME, temperature=0.5)\n",
    "\n",
    "MODEL_NAME = \"llama3.2:latest\"\n",
    "#llm_tool = ChatOllama(model=MODEL_NAME, temperature=0.5)\n",
    "class State(MessagesState):\n",
    "    next: str\n",
    "\n",
    "    \n",
    "call_count = 0\n",
    "call_count_max = 2\n",
    "def supervisor_node(state: State) -> Command[Literal[*members, \"__end__\"]]:\n",
    "    global call_count  # Now it refers to the global variable\n",
    "    global call_count_max\n",
    "\n",
    "    call_count = call_count +1\n",
    "\n",
    "    messages = [\n",
    "        {\"role\": \"system\", \"content\": system_prompt},\n",
    "    ] + state[\"messages\"]\n",
    "    response = llm.with_structured_output(Router).invoke(messages)\n",
    "    goto = response[\"next\"]\n",
    "    if goto == \"FINISH\":\n",
    "        goto = END\n",
    "\n",
    "    if call_count  == call_count_max:\n",
    "        goto = END\n",
    "\n",
    "    return Command(goto=goto, update={\"next\": goto})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = llm.invoke(\"state\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The word \"state\" can have multiple meanings depending on the context. Here are a few possible interpretations:\\n\\n1. **Government or country**: A state can refer to a sovereign entity with its own government, laws, and international recognition. Examples include the United States, China, or France.\\n2. **Condition or status**: A state can describe a particular condition or status of something, such as a state of mind (e.g., happy, sad, or anxious), a state of being (e.g., awake, asleep, or alive), or a state of affairs (e.g., good, bad, or uncertain).\\n3. **Region or territory**: In the United States, a state can refer to one of the 50 constituent entities that make up the country, such as California, New York, or Texas.\\n4. **Science and physics**: In physics, a state can refer to a specific configuration or condition of a system, such as a state of matter (e.g., solid, liquid, or gas) or a quantum state (e.g., a specific energy level or spin orientation).\\n5. **Computer science**: In computer science, a state can refer to the current status or configuration of a system, such as the state of a finite state machine or the state of a software application.\\n\\nWithout more context, it\\'s difficult to determine which meaning is most relevant. If you have any additional information or clarification, I\\'d be happy to try and provide a more specific answer.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 301, 'prompt_tokens': 36, 'total_tokens': 337, 'completion_time': 1.094545455, 'prompt_time': 0.009624793, 'queue_time': 0.241321716, 'total_time': 1.104170248}, 'model_name': 'Llama-3.3-70b-Versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'finish_reason': 'stop', 'logprobs': None}, id='run-a3ac495d-5ee7-48e8-a0e2-ec13adcd5d38-0', usage_metadata={'input_tokens': 36, 'output_tokens': 301, 'total_tokens': 337})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='The word \"state\" can have multiple meanings depending on the context. Here are a few possible interpretations:\\n\\n1. **Government or country**: A state can refer to a sovereign entity with its own government, laws, and international recognition. Examples include the United States, China, or France.\\n2. **Condition or status**: A state can describe a particular condition or status of something, such as a state of mind (e.g., happy, sad, or anxious), a state of being (e.g., awake, asleep, or alive), or a state of affairs (e.g., good, bad, or uncertain).\\n3. **Region or territory**: In the United States, a state can refer to one of the 50 constituent entities that make up the country, such as California, New York, or Texas.\\n4. **Science and physics**: In physics, a state can refer to a specific configuration or condition of a system, such as a state of matter (e.g., solid, liquid, or gas) or a quantum state (e.g., a specific energy level or spin orientation).\\n5. **Computer science**: In computer science, a state can refer to the current status or configuration of a system, such as the state of a finite state machine or the state of a software application.\\n\\nWithout more context, it\\'s difficult to determine which meaning is most relevant. If you have any additional information or clarification, I\\'d be happy to try and provide a more specific answer.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 301, 'prompt_tokens': 36, 'total_tokens': 337, 'completion_time': 1.094545455, 'prompt_time': 0.009624793, 'queue_time': 0.241321716, 'total_time': 1.104170248}, 'model_name': 'Llama-3.3-70b-Versatile', 'system_fingerprint': 'fp_2ddfbb0da0', 'finish_reason': 'stop', 'logprobs': None}, id='run-a3ac495d-5ee7-48e8-a0e2-ec13adcd5d38-0', usage_metadata={'input_tokens': 36, 'output_tokens': 301, 'total_tokens': 337})"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.prebuilt import create_react_agent\n",
    "\n",
    "\n",
    "research_agent = create_react_agent(\n",
    "    llm_tool, tools=[tavily_tool], prompt=\"You are a researcher. DO NOT do any math.\"\n",
    ")\n",
    "\n",
    "\n",
    "def research_node(state: State) -> Command[Literal[\"supervisor\"]]:\n",
    "    #print(\"state:\",state)\n",
    "    result = research_agent.invoke(state)\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(content=result[\"messages\"][-1].content, name=\"researcher\")\n",
    "            ]\n",
    "        },\n",
    "        goto=\"supervisor\",\n",
    "    )\n",
    "\n",
    "\n",
    "# NOTE: THIS PERFORMS ARBITRARY CODE EXECUTION, WHICH CAN BE UNSAFE WHEN NOT SANDBOXED\n",
    "code_agent = create_react_agent(llm, tools=[python_repl_tool])\n",
    "\n",
    "\n",
    "def code_node(state: State) -> Command[Literal[\"supervisor\"]]:\n",
    "    #print(\"state:\",state)\n",
    "    result = code_agent.invoke(state)\n",
    "\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(content=result[\"messages\"][-1].content, name=\"coder\")\n",
    "            ]\n",
    "        },\n",
    "        goto=\"supervisor\",\n",
    "    )\n",
    "\n",
    "\n",
    "import json\n",
    "# Load the JSON file\n",
    "file_path = \"monthly_expenses.json\"  # Replace with the correct path to your file\n",
    "with open(file_path, \"r\") as file:\n",
    "    data = json.load(file)\n",
    "\n",
    "# Convert the JSON data to a string\n",
    "monthly_expenses_json_string = json.dumps(data, indent=4)  # Pretty-printed string\n",
    "\n",
    "expenses_manager_agent = create_react_agent(llm, tools=[custom_summary_report_tool],prompt=f\"You are a expenses manager. you have access to a tool that gives the sumary of the report if the quesiton is not there use this data{monthly_expenses_json_string}\")\n",
    "\n",
    "def expenses_manager_node(state: State) -> Command[Literal[\"supervisor\"]]:\n",
    "\n",
    "    result = expenses_manager_agent.invoke(state)\n",
    "\n",
    "    return Command(\n",
    "        update={\n",
    "            \"messages\": [\n",
    "                HumanMessage(content=result[\"messages\"][-1].content, name=\"expenses_manager\")\n",
    "            ]\n",
    "         \n",
    "        },\n",
    "        goto=\"supervisor\",\n",
    "    )\n",
    "\n",
    "\n",
    "builder = StateGraph(State)\n",
    "builder.add_edge(START, \"supervisor\")\n",
    "builder.add_node(\"supervisor\", supervisor_node)\n",
    "builder.add_node(\"researcher\", research_node)\n",
    "builder.add_node(\"coder\", code_node)\n",
    "builder.add_node(\"expenses_manager\", expenses_manager_node)\n",
    "graph = builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, Image\n",
    "\n",
    "#display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_agent_bot(prompt):\n",
    "    global call_count\n",
    "    global call_count_max\n",
    "\n",
    "    call_count = 0\n",
    "    call_count_max = 2\n",
    "    events = graph.stream(\n",
    "        {\"messages\": [(\"user\", prompt)]}, subgraphs=True\n",
    "    )\n",
    "\n",
    "    my_array = []\n",
    "    for s in events:\n",
    "        print(s)\n",
    "        my_array.append(s)\n",
    "\n",
    "    agents = []\n",
    "    j = -2\n",
    "    for i in range(len(my_array)):\n",
    "        \n",
    "        try:\n",
    "            if my_array[i][1]['supervisor']['next']:  # Check if 'next' key exists and is not empty\n",
    "                \n",
    "\n",
    "                if (j == -2):\n",
    "                    agent =  my_array[i][1]['supervisor']['next']\n",
    "                    print(\"AGENT:\", agent)\n",
    "\n",
    "\n",
    "                j = j+1\n",
    "            \n",
    "                agent =  my_array[i][1]['supervisor']['next']\n",
    "            \n",
    "                agents.append(agent)\n",
    "\n",
    "                #agent = agent.append(my_array[i][1]['supervisor']['next'])\n",
    "                print(my_array[i - 1][1][agents[j]][\"messages\"][0].content)\n",
    "                print(\"-----------\")\n",
    "\n",
    "                print(\"AGENT:\", agent)\n",
    "                \n",
    "                \n",
    "                \n",
    "        except (KeyError, IndexError, TypeError):\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((), {'supervisor': {'next': 'expenses_manager'}})\n",
      "(('expenses_manager:6e544f65-cd4b-5eca-9b12-002b038b1a21',), {'agent': {'messages': [AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_khy0', 'function': {'arguments': '{}', 'name': 'custom_summary_report_tool'}, 'type': 'function'}]}, response_metadata={'token_usage': {'completion_tokens': 11, 'prompt_tokens': 1029, 'total_tokens': 1040, 'completion_time': 0.04, 'prompt_time': 0.106521043, 'queue_time': 0.242548645, 'total_time': 0.146521043}, 'model_name': 'Llama-3.3-70b-Versatile', 'system_fingerprint': 'fp_72a5dc99ee', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-d72f0b61-16a5-4014-bd3a-2d455708fda2-0', tool_calls=[{'name': 'custom_summary_report_tool', 'args': {}, 'id': 'call_khy0', 'type': 'tool_call'}], usage_metadata={'input_tokens': 1029, 'output_tokens': 11, 'total_tokens': 1040})]}})\n",
      "(('expenses_manager:6e544f65-cd4b-5eca-9b12-002b038b1a21',), {'tools': {'messages': [ToolMessage(content='This is the summary report. 2023: Total Food - 99200, Total Transpo - 30900, Total Daily - 18750; 2024: Total Food - 104800, Total Transpo - 32750, Total Daily - 21100', name='custom_summary_report_tool', id='7b3ef6a2-11c2-4bcf-98da-374dc1fa2551', tool_call_id='call_khy0')]}})\n",
      "(('expenses_manager:6e544f65-cd4b-5eca-9b12-002b038b1a21',), {'agent': {'messages': [AIMessage(content='Here is a breakdown of the expenses for each year:\\n\\n2023:\\n- Food: $99,200\\n- Transpo: $30,900\\n- Daily: $18,750\\n\\n2024:\\n- Food: $104,800\\n- Transpo: $32,750\\n- Daily: $21,100\\n\\nPlease note that these figures are calculated based on the provided data and may not reflect any additional expenses or adjustments not included in the data.', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 95, 'prompt_tokens': 1108, 'total_tokens': 1203, 'completion_time': 0.345454545, 'prompt_time': 0.093294626, 'queue_time': 0.243156533, 'total_time': 0.438749171}, 'model_name': 'Llama-3.3-70b-Versatile', 'system_fingerprint': 'fp_72a5dc99ee', 'finish_reason': 'stop', 'logprobs': None}, id='run-2d6e02b5-5075-4ecf-bf78-b9fecc33fc40-0', usage_metadata={'input_tokens': 1108, 'output_tokens': 95, 'total_tokens': 1203})]}})\n",
      "((), {'expenses_manager': {'messages': [HumanMessage(content='Here is a breakdown of the expenses for each year:\\n\\n2023:\\n- Food: $99,200\\n- Transpo: $30,900\\n- Daily: $18,750\\n\\n2024:\\n- Food: $104,800\\n- Transpo: $32,750\\n- Daily: $21,100\\n\\nPlease note that these figures are calculated based on the provided data and may not reflect any additional expenses or adjustments not included in the data.', additional_kwargs={}, response_metadata={}, name='expenses_manager')]}})\n",
      "((), {'supervisor': {'next': '__end__'}})\n",
      "AGENT: expenses_manager\n",
      "Here is a breakdown of the expenses for each year:\n",
      "\n",
      "2023:\n",
      "- Food: $99,200\n",
      "- Transpo: $30,900\n",
      "- Daily: $18,750\n",
      "\n",
      "2024:\n",
      "- Food: $104,800\n",
      "- Transpo: $32,750\n",
      "- Daily: $21,100\n",
      "\n",
      "Please note that these figures are calculated based on the provided data and may not reflect any additional expenses or adjustments not included in the data.\n",
      "-----------\n",
      "AGENT: __end__\n"
     ]
    }
   ],
   "source": [
    "prompt = \"give me a summary of the report of the expenses\"\n",
    "multi_agent_bot(prompt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'2023': {'January': {'Food': 8000, 'Transpo': 2500, 'Daily': 1500},\n",
       "  'February': {'Food': 7500, 'Transpo': 2300, 'Daily': 1400},\n",
       "  'March': {'Food': 8500, 'Transpo': 2600, 'Daily': 1600},\n",
       "  'April': {'Food': 8000, 'Transpo': 2400, 'Daily': 1500},\n",
       "  'May': {'Food': 7800, 'Transpo': 2500, 'Daily': 1450},\n",
       "  'June': {'Food': 8200, 'Transpo': 2600, 'Daily': 1500},\n",
       "  'July': {'Food': 8500, 'Transpo': 2700, 'Daily': 1550},\n",
       "  'August': {'Food': 8700, 'Transpo': 2800, 'Daily': 1600},\n",
       "  'September': {'Food': 8100, 'Transpo': 2400, 'Daily': 1500},\n",
       "  'October': {'Food': 8300, 'Transpo': 2500, 'Daily': 1550},\n",
       "  'November': {'Food': 8600, 'Transpo': 2600, 'Daily': 1600},\n",
       "  'December': {'Food': 9000, 'Transpo': 3000, 'Daily': 2000}},\n",
       " '2024': {'January': {'Food': 8500, 'Transpo': 2600, 'Daily': 1700},\n",
       "  'February': {'Food': 8000, 'Transpo': 2500, 'Daily': 1600},\n",
       "  'March': {'Food': 8700, 'Transpo': 2700, 'Daily': 1750},\n",
       "  'April': {'Food': 8500, 'Transpo': 2600, 'Daily': 1700},\n",
       "  'May': {'Food': 8400, 'Transpo': 2650, 'Daily': 1650},\n",
       "  'June': {'Food': 8600, 'Transpo': 2700, 'Daily': 1700},\n",
       "  'July': {'Food': 8900, 'Transpo': 2800, 'Daily': 1750},\n",
       "  'August': {'Food': 9200, 'Transpo': 2900, 'Daily': 1800},\n",
       "  'September': {'Food': 8700, 'Transpo': 2600, 'Daily': 1700},\n",
       "  'October': {'Food': 8800, 'Transpo': 2700, 'Daily': 1750},\n",
       "  'November': {'Food': 9000, 'Transpo': 2800, 'Daily': 1800},\n",
       "  'December': {'Food': 9500, 'Transpo': 3200, 'Daily': 2200}}}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "    \"2023\": {\n",
      "        \"Total Food\": 99200,\n",
      "        \"Total Transpo\": 30900,\n",
      "        \"Total Daily\": 18750\n",
      "    },\n",
      "    \"2024\": {\n",
      "        \"Total Food\": 104800,\n",
      "        \"Total Transpo\": 32750,\n",
      "        \"Total Daily\": 21100\n",
      "    }\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "def calculate_totals(data):\n",
    "    yearly_totals = {}\n",
    "    for year, months in data.items():\n",
    "        food_total = sum(month[\"Food\"] for month in months.values())\n",
    "        transpo_total = sum(month[\"Transpo\"] for month in months.values())\n",
    "        daily_total = sum(month[\"Daily\"] for month in months.values())\n",
    "        \n",
    "        yearly_totals[year] = {\n",
    "            \"Total Food\": food_total,\n",
    "            \"Total Transpo\": transpo_total,\n",
    "            \"Total Daily\": daily_total\n",
    "        }\n",
    "    return yearly_totals\n",
    "\n",
    "result = calculate_totals(data)\n",
    "print(json.dumps(result, indent=4))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
