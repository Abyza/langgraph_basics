{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "following :\n",
    "\n",
    " https://langchain-ai.github.io/langgraph/tutorials/introduction/#setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langgraph in .\\.venv\\lib\\site-packages (0.3.20)\n",
      "Requirement already satisfied: langsmith in .\\.venv\\lib\\site-packages (0.3.18)\n",
      "Requirement already satisfied: langchain_anthropic in .\\.venv\\lib\\site-packages (0.3.10)\n",
      "Requirement already satisfied: langchain-core<0.4,>=0.1 in .\\.venv\\lib\\site-packages (from langgraph) (0.3.48)\n",
      "Requirement already satisfied: langgraph-checkpoint<3.0.0,>=2.0.10 in .\\.venv\\lib\\site-packages (from langgraph) (2.0.23)\n",
      "Requirement already satisfied: langgraph-prebuilt<0.2,>=0.1.1 in .\\.venv\\lib\\site-packages (from langgraph) (0.1.4)\n",
      "Requirement already satisfied: xxhash<4.0.0,>=3.5.0 in .\\.venv\\lib\\site-packages (from langgraph) (3.5.0)\n",
      "Requirement already satisfied: langgraph-sdk<0.2.0,>=0.1.42 in .\\.venv\\lib\\site-packages (from langgraph) (0.1.58)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in .\\.venv\\lib\\site-packages (from langsmith) (1.0.0)\n",
      "Requirement already satisfied: pydantic<3,>=1 in .\\.venv\\lib\\site-packages (from langsmith) (2.10.6)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in .\\.venv\\lib\\site-packages (from langsmith) (3.10.16)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in .\\.venv\\lib\\site-packages (from langsmith) (0.28.1)\n",
      "Requirement already satisfied: packaging>=23.2 in .\\.venv\\lib\\site-packages (from langsmith) (24.2)\n",
      "Requirement already satisfied: requests<3,>=2 in .\\.venv\\lib\\site-packages (from langsmith) (2.32.3)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in .\\.venv\\lib\\site-packages (from langsmith) (0.23.0)\n",
      "Requirement already satisfied: anthropic<1,>=0.49.0 in .\\.venv\\lib\\site-packages (from langchain_anthropic) (0.49.0)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in .\\.venv\\lib\\site-packages (from anthropic<1,>=0.49.0->langchain_anthropic) (1.9.0)\n",
      "Requirement already satisfied: jiter<1,>=0.4.0 in .\\.venv\\lib\\site-packages (from anthropic<1,>=0.49.0->langchain_anthropic) (0.9.0)\n",
      "Requirement already satisfied: sniffio in .\\.venv\\lib\\site-packages (from anthropic<1,>=0.49.0->langchain_anthropic) (1.3.1)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in .\\.venv\\lib\\site-packages (from anthropic<1,>=0.49.0->langchain_anthropic) (4.9.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in .\\.venv\\lib\\site-packages (from anthropic<1,>=0.49.0->langchain_anthropic) (4.12.2)\n",
      "Requirement already satisfied: certifi in .\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith) (2025.1.31)\n",
      "Requirement already satisfied: idna in .\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith) (3.10)\n",
      "Requirement already satisfied: httpcore==1.* in .\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->langsmith) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in .\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->langsmith) (0.14.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in .\\.venv\\lib\\site-packages (from langchain-core<0.4,>=0.1->langgraph) (1.33)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in .\\.venv\\lib\\site-packages (from langchain-core<0.4,>=0.1->langgraph) (9.0.0)\n",
      "Requirement already satisfied: PyYAML>=5.3 in .\\.venv\\lib\\site-packages (from langchain-core<0.4,>=0.1->langgraph) (6.0.2)\n",
      "Requirement already satisfied: ormsgpack<2.0.0,>=1.8.0 in .\\.venv\\lib\\site-packages (from langgraph-checkpoint<3.0.0,>=2.0.10->langgraph) (1.9.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in .\\.venv\\lib\\site-packages (from pydantic<3,>=1->langsmith) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in .\\.venv\\lib\\site-packages (from pydantic<3,>=1->langsmith) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in .\\.venv\\lib\\site-packages (from requests<3,>=2->langsmith) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in .\\.venv\\lib\\site-packages (from requests<3,>=2->langsmith) (2.3.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in .\\.venv\\lib\\site-packages (from anyio<5,>=3.5.0->anthropic<1,>=0.49.0->langchain_anthropic) (1.2.2)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in .\\.venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4,>=0.1->langgraph) (3.0.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -U langgraph langsmith langchain_anthropic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: python-dotenv in .\\.venv\\lib\\site-packages (1.0.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install python-dotenv\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: langchain_groq in .\\.venv\\lib\\site-packages (0.3.1)\n",
      "Requirement already satisfied: groq<1,>=0.4.1 in .\\.venv\\lib\\site-packages (from langchain_groq) (0.20.0)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.47 in .\\.venv\\lib\\site-packages (from langchain_groq) (0.3.48)\n",
      "Requirement already satisfied: anyio<5,>=3.5.0 in .\\.venv\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (4.9.0)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in .\\.venv\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (4.12.2)\n",
      "Requirement already satisfied: httpx<1,>=0.23.0 in .\\.venv\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (0.28.1)\n",
      "Requirement already satisfied: distro<2,>=1.7.0 in .\\.venv\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (1.9.0)\n",
      "Requirement already satisfied: pydantic<3,>=1.9.0 in .\\.venv\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (2.10.6)\n",
      "Requirement already satisfied: sniffio in .\\.venv\\lib\\site-packages (from groq<1,>=0.4.1->langchain_groq) (1.3.1)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in .\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.47->langchain_groq) (24.2)\n",
      "Requirement already satisfied: PyYAML>=5.3 in .\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.47->langchain_groq) (6.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in .\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.47->langchain_groq) (1.33)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10.0.0,>=8.1.0 in .\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.47->langchain_groq) (9.0.0)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in .\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.47->langchain_groq) (0.3.18)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in .\\.venv\\lib\\site-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain_groq) (1.2.2)\n",
      "Requirement already satisfied: idna>=2.8 in .\\.venv\\lib\\site-packages (from anyio<5,>=3.5.0->groq<1,>=0.4.1->langchain_groq) (3.10)\n",
      "Requirement already satisfied: certifi in .\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in .\\.venv\\lib\\site-packages (from httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in .\\.venv\\lib\\site-packages (from httpcore==1.*->httpx<1,>=0.23.0->groq<1,>=0.4.1->langchain_groq) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in .\\.venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.47->langchain_groq) (3.0.0)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in .\\.venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.47->langchain_groq) (0.23.0)\n",
      "Requirement already satisfied: requests<3,>=2 in .\\.venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.47->langchain_groq) (2.32.3)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in .\\.venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.47->langchain_groq) (1.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in .\\.venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.47->langchain_groq) (3.10.16)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in .\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain_groq) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in .\\.venv\\lib\\site-packages (from pydantic<3,>=1.9.0->groq<1,>=0.4.1->langchain_groq) (2.27.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in .\\.venv\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.47->langchain_groq) (3.4.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in .\\.venv\\lib\\site-packages (from requests<3,>=2->langsmith<0.4,>=0.1.125->langchain-core<1.0.0,>=0.3.47->langchain_groq) (2.3.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install langchain_groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import getpass\n",
    "import os\n",
    "from dotenv import find_dotenv, load_dotenv\n",
    "\n",
    "dotenv_path = find_dotenv()\n",
    "load_dotenv(dotenv_path)\n",
    "groq_api_key = os.getenv(\"groq_api_key\")\n",
    "os.environ[\"groq_api_key\"] = groq_api_key \n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "\n",
    "_set_env(\"groq_api_key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'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'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ.get(\"groq_api_key\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    # Messages have the type \"list\". The `add_messages` function\n",
    "    # in the annotation defines how this state key should be updated\n",
    "    # (in this case, it appends messages to the list, rather than overwriting them)\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x2ce9d927370>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_anthropic import ChatAnthropic\n",
    "from langchain_groq import ChatGroq\n",
    "#llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")\n",
    "llm=ChatGroq(groq_api_key=groq_api_key,model_name=\"Gemma2-9b-It\")\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "# The first argument is the unique node name\n",
    "# The second argument is the function or object that will be called whenever\n",
    "# the node is used.\n",
    "graph_builder.add_node(\"chatbot\", chatbot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "graph_builder.add_edge(\"chatbot\", END)\n",
    "graph = graph_builder.compile()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "try:\n",
    "    display(Image(graph.get_graph().draw_mermaid_png()))\n",
    "except Exception:\n",
    "    # This requires some extra dependencies and is optional\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assistant: I am Gemma, an open-weights AI assistant. I am a large language model trained by Google DeepMind.\n",
      "\n",
      "Here are some key things to know about me:\n",
      "\n",
      "* **Open-weights:** My weights are publicly accessible. This means anyone can see, study, and modify me.\n",
      "* **Text-only:** I can only communicate through text. I can't generate images, sound, or videos.\n",
      "* **Limited knowledge:** I was trained on a massive dataset of text, but my knowledge is only up to a certain point in time. I don't have access to real-time information or Google Search.\n",
      "* **Created by the Gemma team:** I was developed by a team of engineers and researchers at Google DeepMind.\n",
      "\n",
      "I'm here to help with a variety of tasks, such as:\n",
      "\n",
      "* Answering your questions\n",
      "* Generating creative text formats\n",
      "* Translating languages\n",
      "* Summarizing text\n",
      "* And much more!\n",
      "\n",
      "Just keep in mind my limitations. I'm still under development and learning new things every day.\n",
      "\n",
      "Assistant: I am Gemma, an open-weights AI assistant. I am a large language model trained by Google DeepMind.\n",
      "\n",
      "Here's what that means:\n",
      "\n",
      "* **Open-weights:** My weights are publicly accessible. This means anyone can see the underlying code and data that make me work.\n",
      "* **AI assistant:** I'm designed to help people with various tasks, such as:\n",
      "\n",
      "Generating text,\n",
      "\n",
      "Answering questions,\n",
      "\n",
      "Summarizing information,\n",
      "\n",
      "Translating languages,\n",
      "\n",
      "And more.\n",
      "\n",
      "* **Large language model:** I've been trained on a massive dataset of text and code, which allows me to understand and generate human-like text.\n",
      "\n",
      "I am still under development, but I'm learning new things every day.\n",
      "\n",
      "Assistant: I'm glad you think so! Is there anything I can help you with? 😊  \n",
      "\n",
      "\n",
      "Assistant: Please provide me with some context! \"What is it again\" refers to something that was previously mentioned. I need to know what \"it\" is in order to answer your question. \n",
      "\n",
      "For example, you could say:\n",
      "\n",
      "* \"What is the capital of France again?\"\n",
      "* \"What is that thing you were talking about earlier again?\"\n",
      "* \"What is the name of that movie we watched again?\"\n",
      "\n",
      "\n",
      "Let me know what you're thinking of! 😊\n",
      "\n",
      "\n",
      "Goodbye!\n"
     ]
    }
   ],
   "source": [
    "def stream_graph_updates(user_input: str):\n",
    "    for event in graph.stream({\"messages\": [{\"role\": \"user\", \"content\": user_input}]}):\n",
    "        for value in event.values():\n",
    "            print(\"Assistant:\", value[\"messages\"][-1].content)\n",
    "\n",
    "\n",
    "while True:\n",
    "    try:\n",
    "        user_input = input(\"User: \")\n",
    "        if user_input.lower() in [\"quit\", \"exit\", \"q\"]:\n",
    "            print(\"Goodbye!\")\n",
    "            break\n",
    "\n",
    "        stream_graph_updates(user_input)\n",
    "    except:\n",
    "        # fallback if input() is not available\n",
    "        user_input = \"What do you know about LangGraph?\"\n",
    "        print(\"User: \" + user_input)\n",
    "        stream_graph_updates(user_input)\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PART 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "dotenv_path = find_dotenv()\n",
    "load_dotenv(dotenv_path)\n",
    "tavily_api_key = os.getenv(\"tavily_api_key\")\n",
    "os.environ[\"tavily_api_key\"] = tavily_api_key\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"tavily_api_key\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting tavily-python\n",
      "  Downloading tavily_python-0.5.1-py3-none-any.whl (43 kB)\n",
      "     ---------------------------------------- 0.0/43.8 kB ? eta -:--:--\n",
      "     ---------------------------------------- 43.8/43.8 kB ? eta 0:00:00\n",
      "Collecting langchain_community\n",
      "  Using cached langchain_community-0.3.20-py3-none-any.whl (2.5 MB)\n",
      "Requirement already satisfied: requests in .\\.venv\\lib\\site-packages (from tavily-python) (2.32.3)\n",
      "Collecting tiktoken>=0.5.1\n",
      "  Downloading tiktoken-0.9.0-cp310-cp310-win_amd64.whl (894 kB)\n",
      "     ---------------------------------------- 0.0/894.0 kB ? eta -:--:--\n",
      "     -------------- ---------------------- 358.4/894.0 kB 11.2 MB/s eta 0:00:01\n",
      "     ------------------------------------- 894.0/894.0 kB 14.3 MB/s eta 0:00:00\n",
      "Requirement already satisfied: httpx in .\\.venv\\lib\\site-packages (from tavily-python) (0.28.1)\n",
      "Collecting pydantic-settings<3.0.0,>=2.4.0\n",
      "  Using cached pydantic_settings-2.8.1-py3-none-any.whl (30 kB)\n",
      "Collecting numpy<3,>=1.26.2\n",
      "  Using cached numpy-2.2.4-cp310-cp310-win_amd64.whl (12.9 MB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in .\\.venv\\lib\\site-packages (from langchain_community) (6.0.2)\n",
      "Requirement already satisfied: langchain-core<1.0.0,>=0.3.45 in .\\.venv\\lib\\site-packages (from langchain_community) (0.3.48)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7\n",
      "  Using cached dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Collecting SQLAlchemy<3,>=1.4\n",
      "  Using cached sqlalchemy-2.0.39-cp310-cp310-win_amd64.whl (2.1 MB)\n",
      "Collecting httpx-sse<1.0.0,>=0.4.0\n",
      "  Using cached httpx_sse-0.4.0-py3-none-any.whl (7.8 kB)\n",
      "Collecting langchain<1.0.0,>=0.3.21\n",
      "  Using cached langchain-0.3.21-py3-none-any.whl (1.0 MB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3\n",
      "  Using cached aiohttp-3.11.14-cp310-cp310-win_amd64.whl (442 kB)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<10,>=8.1.0 in .\\.venv\\lib\\site-packages (from langchain_community) (9.0.0)\n",
      "Requirement already satisfied: langsmith<0.4,>=0.1.125 in .\\.venv\\lib\\site-packages (from langchain_community) (0.3.18)\n",
      "Collecting frozenlist>=1.1.1\n",
      "  Using cached frozenlist-1.5.0-cp310-cp310-win_amd64.whl (51 kB)\n",
      "Collecting async-timeout<6.0,>=4.0\n",
      "  Downloading async_timeout-5.0.1-py3-none-any.whl (6.2 kB)\n",
      "Collecting attrs>=17.3.0\n",
      "  Using cached attrs-25.3.0-py3-none-any.whl (63 kB)\n",
      "Collecting aiohappyeyeballs>=2.3.0\n",
      "  Using cached aiohappyeyeballs-2.6.1-py3-none-any.whl (15 kB)\n",
      "Collecting multidict<7.0,>=4.5\n",
      "  Using cached multidict-6.2.0-cp310-cp310-win_amd64.whl (29 kB)\n",
      "Collecting aiosignal>=1.1.2\n",
      "  Using cached aiosignal-1.3.2-py2.py3-none-any.whl (7.6 kB)\n",
      "Collecting yarl<2.0,>=1.17.0\n",
      "  Using cached yarl-1.18.3-cp310-cp310-win_amd64.whl (90 kB)\n",
      "Collecting propcache>=0.2.0\n",
      "  Using cached propcache-0.3.0-cp310-cp310-win_amd64.whl (44 kB)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0\n",
      "  Using cached marshmallow-3.26.1-py3-none-any.whl (50 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0\n",
      "  Using cached typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Collecting langchain-text-splitters<1.0.0,>=0.3.7\n",
      "  Using cached langchain_text_splitters-0.3.7-py3-none-any.whl (32 kB)\n",
      "Collecting async-timeout<6.0,>=4.0\n",
      "  Using cached async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.7.4 in .\\.venv\\lib\\site-packages (from langchain<1.0.0,>=0.3.21->langchain_community) (2.10.6)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in .\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.45->langchain_community) (1.33)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in .\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.45->langchain_community) (4.12.2)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in .\\.venv\\lib\\site-packages (from langchain-core<1.0.0,>=0.3.45->langchain_community) (24.2)\n",
      "Requirement already satisfied: zstandard<0.24.0,>=0.23.0 in .\\.venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain_community) (0.23.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in .\\.venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain_community) (3.10.16)\n",
      "Requirement already satisfied: requests-toolbelt<2.0.0,>=1.0.0 in .\\.venv\\lib\\site-packages (from langsmith<0.4,>=0.1.125->langchain_community) (1.0.0)\n",
      "Requirement already satisfied: anyio in .\\.venv\\lib\\site-packages (from httpx->tavily-python) (4.9.0)\n",
      "Requirement already satisfied: idna in .\\.venv\\lib\\site-packages (from httpx->tavily-python) (3.10)\n",
      "Requirement already satisfied: certifi in .\\.venv\\lib\\site-packages (from httpx->tavily-python) (2025.1.31)\n",
      "Requirement already satisfied: httpcore==1.* in .\\.venv\\lib\\site-packages (from httpx->tavily-python) (1.0.7)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in .\\.venv\\lib\\site-packages (from httpcore==1.*->httpx->tavily-python) (0.14.0)\n",
      "Requirement already satisfied: python-dotenv>=0.21.0 in .\\.venv\\lib\\site-packages (from pydantic-settings<3.0.0,>=2.4.0->langchain_community) (1.0.1)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in .\\.venv\\lib\\site-packages (from requests->tavily-python) (2.3.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in .\\.venv\\lib\\site-packages (from requests->tavily-python) (3.4.1)\n",
      "Collecting greenlet!=0.4.17\n",
      "  Using cached greenlet-3.1.1-cp310-cp310-win_amd64.whl (298 kB)\n",
      "Collecting regex>=2022.1.18\n",
      "  Using cached regex-2024.11.6-cp310-cp310-win_amd64.whl (274 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in .\\.venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<1.0.0,>=0.3.45->langchain_community) (3.0.0)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in .\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.21->langchain_community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.27.2 in .\\.venv\\lib\\site-packages (from pydantic<3.0.0,>=2.7.4->langchain<1.0.0,>=0.3.21->langchain_community) (2.27.2)\n",
      "Collecting mypy-extensions>=0.3.0\n",
      "  Using cached mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Requirement already satisfied: sniffio>=1.1 in .\\.venv\\lib\\site-packages (from anyio->httpx->tavily-python) (1.3.1)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in .\\.venv\\lib\\site-packages (from anyio->httpx->tavily-python) (1.2.2)\n",
      "Installing collected packages: regex, propcache, numpy, mypy-extensions, multidict, marshmallow, httpx-sse, greenlet, frozenlist, attrs, async-timeout, aiohappyeyeballs, yarl, typing-inspect, tiktoken, SQLAlchemy, aiosignal, tavily-python, pydantic-settings, dataclasses-json, aiohttp, langchain-text-splitters, langchain, langchain_community\n",
      "Successfully installed SQLAlchemy-2.0.39 aiohappyeyeballs-2.6.1 aiohttp-3.11.14 aiosignal-1.3.2 async-timeout-4.0.3 attrs-25.3.0 dataclasses-json-0.6.7 frozenlist-1.5.0 greenlet-3.1.1 httpx-sse-0.4.0 langchain-0.3.21 langchain-text-splitters-0.3.7 langchain_community-0.3.20 marshmallow-3.26.1 multidict-6.2.0 mypy-extensions-1.0.0 numpy-2.2.4 propcache-0.3.0 pydantic-settings-2.8.1 regex-2024.11.6 tavily-python-0.5.1 tiktoken-0.9.0 typing-inspect-0.9.0 yarl-1.18.3\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 23.0.1 -> 25.0.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "%pip install -U tavily-python langchain_community"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'title': 'LangGraph Glossary - GitHub Pages',\n",
       "  'url': 'https://langchain-ai.github.io/langgraph/concepts/low_level/',\n",
       "  'content': 'In LangGraph, nodes are typically python functions (sync or async) where the first positional argument is the state, and (optionally), the second positional argument is a \"config\", containing optional configurable parameters (such as a thread_id).\\nSimilar to NetworkX, you add these nodes to a graph using the add_node method:\\n[](https://langchain-ai.github.io/langgraph/concepts/low_level/#__codelineno-7-1)from langchain_core.runnables import RunnableConfig [...] By composing Nodes and Edges, you can create complex, looping workflows that evolve the State over time. The real power, though, comes from how LangGraph manages that State. To emphasize: Nodes and Edges are nothing more than Python functions - they can contain an LLM or just good ol\\' Python code.\\nIn short: nodes do the work. edges tell what to do next. [...] Nodes: Python functions that encode the logic of your agents. They receive the current State as input, perform some computation or side-effect, and return an updated State.\\n\\n\\nEdges: Python functions that determine which Node to execute next based on the current State. They can be conditional branches or fixed transitions.',\n",
       "  'score': 0.9008183},\n",
       " {'title': 'LangGraph Glossary - GitHub Pages',\n",
       "  'url': 'https://langchain-ai.github.io/langgraphjs/concepts/low_level/',\n",
       "  'content': 'In LangGraph, nodes are typically JavaScript/TypeScript functions (sync or async) where the first positional argument is the state, and (optionally), the second positional argument is a \"config\", containing optional configurable parameters (such as a thread_id).\\nSimilar to NetworkX, you add these nodes to a graph using the addNode method:\\n[](https://langchain-ai.github.io/langgraphjs/concepts/low_level/#__codelineno-10-1)import{RunnableConfig}from\"@langchain/core/runnables\"; [...] By composing Nodes and Edges, you can create complex, looping workflows that evolve the State over time. The real power, though, comes from how LangGraph manages that State. To emphasize: Nodes and Edges are nothing more than JavaScript/TypeScript functions - they can contain an LLM or just good ol\\' JavaScript/TypeScript code.\\nIn short: nodes do the work. edges tell what to do next. [...] Nodes: JavaScript/TypeScript functions that encode the logic of your agents. They receive the current State as input, perform some computation or side-effect, and return an updated State.\\n\\n\\nEdges: JavaScript/TypeScript functions that determine which Node to execute next based on the current State. They can be conditional branches or fixed transitions.',\n",
       "  'score': 0.8974172}]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_community.tools.tavily_search import TavilySearchResults\n",
    "\n",
    "tool = TavilySearchResults(max_results=2)\n",
    "tools = [tool]\n",
    "tool.invoke(\"What's a 'node' in LangGraph?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<langgraph.graph.state.StateGraph at 0x2ce9f787970>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain_anthropic import ChatAnthropic\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "\n",
    "\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "\n",
    "#llm = ChatAnthropic(model=\"claude-3-5-sonnet-20240620\")\n",
    "llm=ChatGroq(groq_api_key=groq_api_key,model_name=\"Gemma2-9b-It\")\n",
    "# Modification: tell the LLM which tools it can call\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "\n",
    "def chatbot(state: State):\n",
    "    return {\"messages\": [llm_with_tools.invoke(state[\"messages\"])]}\n",
    "\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
